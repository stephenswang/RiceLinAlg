

\beginedxvertical{Page One}

\beginedxtext{Preliminaries}





At the end of this sequence, and after some practice, you should be able to:

\begin{itemize} 
\item Dimension... 
\end{itemize}


For time budgeting purposes, this sequence has x videos totaling X minutes, 
plus some questions.  




\endedxtext

\endedxvertical








\beginedxvertical{Coordinates Continued}



\doedxvideo{Coordinatization}{sNoKjBJ9tpE}


\beginedxtext{Coordinatization as Linear Transformation}

{\keya{\bf{Proposition.}}}  If $\mathcal{B}  = \{v_1; v_2; \ldots ; v_n\}$ is a basis of $V$, then the
coordinatization map $C: V \rightarrow \R^n$ given by $C(w) = [w]_{\mathcal{B}}$ is a linear transformation
which is both into and onto.

\begin{edXshowhide}{Proof of Proposition}
In the video, we proved that $C$ is into and onto, but we did not show that $C$ is a linear transformation.
We do that here.  

To show that $C$ is a linear transformation, we must show that $C$ respects vector addition and 
scalar multiplication.  

Let $u, w \in W$.  Suppose that
\[
C(u) = \left[ \begin{array}{c} a_1 \\ a_2 \\ \vdots \\ a_n \end{array} \right], 
C(w) = \left[ \begin{array}{c} b_1 \\ b_2 \\ \vdots \\ b_n \end{array} \right].\]
Then we must have $u = a_1v_1 + a_2v_2 + \ldots a_n v_n,$ and 
$w = b_1v_1 + b_2v_2 + \ldots b_n v_n.$  Adding, we see that
\[u+w = (a_1+b_1)v_1 + (a_2+b_2)v_2 + \ldots + (a_n+b_n)v_n.\]
In other words, the coordinates of $u+w$ relative to $\mathcal{B}$ are 
\[C(u+w) = [u+w]_{\mathcal{B}} = \left[ \begin{array}{c} a_1+b_1 \\ a_2+b_2 \\ \vdots \\ a_n+b_n \end{array} \right].\]
But this is exactly $C(u) + C(w)$.  Thus $C$ respects vector addition.  

Now let $u$ be as above, and let $c$ be any scalar.  Then 
\[cu = (ca_1)v_1 + (ca_2)v_2 + \ldots + (ca_n)v_n.\]
Therefore the coordinates of $cu$ are
\[C(cu) = [cu]_{\mathcal{B}} = \left[ \begin{array}{c} ca_1 \\ ca_2 \\ \vdots \\ ca_n \end{array} \right] =
cC(u).\]
Therefore $C$ respects scalar multiplication, and $C$ is a linear transformation.  




\end{edXshowhide}



{\keya{\bf{Proposition.}}}  If $\mathcal{B}  = \{v_1; v_2; \ldots ; v_n\}$ is a basis of $V$, and $k>n$, then any list
of $k$ vectors in $V$ must be linearly dependent.  

\endedxtext


\endedxvertical




\beginedxvertical{Further Consequences}


\beginedxproblem{Two Bases? 1}{\dpa1}


Recall the proposition we just proved: 

{\keya{\bf{Proposition.}}}  If $\mathcal{B}  = \{v_1; v_2; \ldots ; v_n\}$ is a basis of $V$, and $k>n$, then any list
of $k$ vectors in $V$ must be linearly dependent.  

Now suppose that $\mathcal{B}$ is a basis of $V$ with 5 vectors, and let $\mathcal{C}$ be a list of 7 vectors
in $V$.  Is it possible for $\mathcal{C}$ to be a basis of $V$?  


\edXabox{expect="No" options="Yes","No"}

\edXsolution{No.  Since $V$ has a basis which contains 5 vectors, the list $C$, which contains 7 vectors, must be linearly dependent.  By definition, a linearly dependent list cannot form a basis.
}

\endedxproblem


\beginedxproblem{Two Bases? 2}{\dpa1}

Now suppose that $\mathcal{C}$ is a basis of $V$ with 7 vectors.  Is it possible for there to be a basis $\mathcal{B}$ of $V$ with 5 vectors?  


\edXabox{expect="No" options="Yes","No"}

\edXsolution{If $\mathcal{B}$ is a list containing 5 vectors and forms a basis for $V$, then the list $\mathcal{C}$, which contains 7 vectors, must be linearly dependent.  But, by definition, a linearly dependent list cannot be a basis.  This contradicts the assumption that $\mathcal{C}$ formed a basis for $V$.
}

\endedxproblem

\endedxvertical




\beginedxvertical{Dimension}



\doedxvideo{Dimension}{gKmyYkYB0Qo}

\beginedxtext{Dimension Definition}

{\keya{\bf{Proposition.}}}  All bases of a vector space $V$ must have the same number of vectors.  
  

{\keya{\bf{Definition.}}}  
The {\keyb{\bf{dimension}}} of a vector space $V$ is defined to be the number of vectors in 
a basis of $V$.  If $V$ has no finite basis, we say that $V$ is infinite-dimensional.  


\endedxtext


\beginedxproblem{Dimension Question 1}{\dpa1}

True or False: If the dimension of $V$ is 4, then every list of 4 vectors in $V$ must be a basis of $V$.  

\edXabox{expect="False" options="True","False"}

\edXsolution{False.  For example,  $\R^4$ has dimension 4.  The list $\{e_1; 2e_1; 3e_1; 4e_1\}$ contains 4 vectors, but they are linearly dependent and thus the list is not a basis of $\R^4$.  
}

\endedxproblem



\beginedxproblem{Dimension Question 2}{\dpa1}

True or False: If the dimension of $V$ is 6, then there must exist a basis of $V$ with exactly 6 vectors.

\edXabox{expect="True" options="True","False"}

\edXsolution{We are assuming that $V$ has dimension 6.  In order to define the dimension of $V$, there must be a basis of $V$ containing 6 vectors.
}

\endedxproblem

\beginedxproblem{Dimension Question 3}{\dpa1}

Let $V = \R^2$.  What is the dimension of $V$?  

\edXabox{type="numerical" expect="2"}

\edXsolution{The list of vectors $$\{e_1; e_2\}=\left\{\left[ \begin{array}{c} 1 \\ 0 \end{array} \right]; \left[ \begin{array}{c} 0 \\ 1 \end{array} \right]\right\}$$ forms a basis for $\R^2$.  Thus $\R^2$ is 2-dimensional. 
}

\endedxproblem


\beginedxproblem{Dimension Question 4}{\dpa1}


\begin{center}
\includesvg[450]{c3s2dimension}
\end{center}

Let $W$ be the subspace of $\R^2$ drawn above.  What is the dimension of $W$?  


\edXabox{type="numerical" expect="1"}

\edXsolution{If we take $v$ to be a vector of any length that lies in the direction of $W$, then the set of linear combinations of $v$ will be all of $W$.  Then, $\{v\}$ is a linearly independent list that spans $W$, and thus $\{v\}$ is a basis of $W$.  By definition, the dimension of $W$ is the number of vectors in any basis for $W$.  This is 1.
}

\endedxproblem


\endedxvertical




\beginedxvertical{Dimension and Subspaces}



\doedxvideo{Dimension and Subspaces}{5mlxz2ysoEg}


\beginedxtext{Dimension Propositions}

{\keya{\bf{Proposition (A).}}}  If $\dim V = n < \infty$, and $W$ is any subspace of $V$, then any
linearly independent list of vectors in $W$ can be extended to form a basis of $W$.  

{\keya{\bf{Proposition.}}} If $\dim V = n$, then any linearly independent list of vectors in $V$ has
at most $n$ vectors.  Any linearly independent list of vectors in $V$ that has exactly $n$ vectors must
be a basis of $V$.  


{\keya{\bf{Proposition.}}} If $\dim V = n$, then any subspace $W$ of $V$ has dimension at most $n$.  
If $\dim W = n$, then $W = V$.  


{\keya{\bf{Proposition (B).}}} Any finite list of vectors that spans a vector space $V$ contains a basis of $V$.  

{\keya{\bf{Proposition.}}} If $\dim V = n$, then any list of vectors that spans $V$ has
at least $n$ vectors.  Any  list of vectors that spans $V$ that has exactly $n$ vectors must
be a basis of $V$.  


\begin{edXshowhide}{Proof of Proposition (A)}

We will first show that if a linearly independent list of vectors in $W$ is not a basis of $W$, then
there is a vector in $W$ which can be added to the list maintaining linear independence.  

Let $\mathcal{L} = \{w_1; w_2; \ldots w_k\}$ be a linearly independent list of vectors in $W$.  If
$\mathcal{L}$ spans $W$, then it is a basis of $W$.  Therefore we assume that $\mathcal{L}$ is not
a basis of $W$.  In particular, it does not span $W$, so we can find some vector $v\in W$ which is
not a linear combination of $w_1, w_2, \ldots w_k$.  Appending $v$ to the list $\mathcal{L}$
yields a new list $\mathcal{L'}=\{w_1; w_2; \ldots w_k; v\}$; we claim that $\mathcal{L'}$ 
 is still linearly independent.  
 
To show this, suppose that we have a linear combination
\[a_1w_1 + a_2w_2 + \ldots + a_k w_k + bv = \veco.\]  
If $b\ne 0$, then we obtain
\[ -bv = a_1w_1 + a_2w_2 + \ldots + a_k w_k,\]
and hence 
\[v = -\frac{a_1}{b}w_1 + -\frac{a_2}{b}w_2 + \ldots + -\frac{a_k}{b}w_k.\]
But we know that $v$ is not in the span of $\mathcal{L}=\{w_1; w_2; \ldots w_k\}$, so this is impossible.  
Hence $b = 0$.  

Therefore our linear combination becomes
\[a_1w_1 + a_2w_2 + \ldots + a_k w_k + 0v = \veco,\] 
so we have 
\[a_1w_1 + a_2w_2 + \ldots + a_k w_k  = \veco.\] 
However, we know that $\mathcal{L}=\{w_1; w_2; \ldots w_k\}$ is linearly independent, so all
of the $a_i$ must be zero as well.  Therefore all of the coefficients of the original linear combination
must be zero, and we have shown that the new list $\mathcal{L'}$ is linearly independent.  

Therefore, we can keep adding vectors to the list, maintaining
linear independence, as long as the list does not span $W$.  This procedure cannot go on forever, though,
since we know that no list of more than $n$ vectors in $V$ can be linearly independent.  Therefore
at some point we must reach a linearly independent list which also spans $W$; in other words, a basis
of $W$.  This proves the proposition.  

\end{edXshowhide}


\begin{edXshowhide}{Proof of Proposition (B)}

We will first show that if a finite, linearly dependent list of vectors spans $W$, then
there is a vector in the list which can be deleted from the list so that the 
remaining vectors still span $W$.  

Suppose that $\{w_1; w_2; \ldots w_k\}$ spans $W$.  If the list is linearly dependent, then one of the
vectors can be written as a linear combination of the others.  For ease of notation, suppose that $w_1$
is that vector, and that $w_1 = a_2w_2 + a_3w_3 +\ldots + a_kw_k$.  

We claim that $\{w_2; w_3; \ldots w_k\}$ still spans $W$.  Indeed, let $u \in W$.  Since the original
list spans $W$, we know that we can write $u$ as a linear combination
\[u = c_1w_1 + c_2w_2 + \ldots + c_kw_k.\]
Replacing $w_1$, we obtain
\[
\begin{array}{rcl} u & = & c_1(a_2w_2 + a_3w_3 +\ldots + a_kw_k) + c_2w_2 + \ldots + c_kw_k  \\
& = & (c_1a_2+c_2)w_2 + \ldots + (c_1a_k + c_k)w_k. 
\end{array}
\]
Hence $u$ can be written as a linear combination of just $\{w_2; w_3; \ldots w_k\},$
and the smaller list still spans $W$.  

Thus, as long as the list remains linearly dependent, we can keep deleting vectors from the list
and maintain the property that the list spans $W$.  Since the initial list is finite, however,
this procedure must stop.  Thus we eventually have pared the list down to a list which still spans
$W$ but is also linearly independent; in other words, we obtain a basis of $W$.  This proves the
proposition.

\end{edXshowhide}



\endedxtext

\endedxvertical




\beginedxvertical{Polynomial Subspace Questions}

\beginedxproblem{Polynomial Dimension 1}{\dpa2}
The questions on this page will help us figure out the dimension of the space of polynomials $\mathbb{P}$.  

Recall that $\mathbb{P}_n$ is the set of polynomials with real coefficients of degree at most $n$.  
What is the dimension of $\mathbb{P}_4$?  

\edXabox{type="numerical" expect="5"}

\edXsolution{Recall that the list $\{1; t; t^2; t^3; t^4\}$ forms a basis of $\mathbb{P}_4$, so the
dimension is 5.  
}

\endedxproblem

\beginedxproblem{Polynomial Dimension 2}{\dpa2}

If a vector space $V$ contains $\mathbb{P}_4$ as a subspace, what is the smallest possible dimension of $V$?

\edXabox{type="numerical" expect="5"}

\edXsolution{We have shown that the dimension of a subspace can be at most equal to the dimension of the space it is contained in.  Note that $V$ could equal $\mathbb{P}_4$, which would give us $\dim V = 5$.  
}

\endedxproblem


\beginedxproblem{Polynomial Dimension 3}{\dpa2}

Note that, in particular, the space $\mathbb{P}$ contains $\mathbb{P}_4$ as a subspace, so we can arrive
at the same conclusion about the dimension of $\mathbb{P}$ as we did for $V$ in the previous question.  

However, $\mathbb{P}$ also contains $\mathbb{P}_{40}$, $\mathbb{P}_{400}$, and
$\mathbb{P}_{4000}$ as subspaces (among others).  What can we conclude about the dimension of
$\mathbb{P}$?  

\edXabox{expect="It is infinite dimensional" options="It has dimension 5","It has dimension 41","It has dimension 4001","It is infinite dimensional"}

\edXsolution{
Since $\mathbb{P}$ contains $\mathbb{P}_{4000}$ (a 4001-dimensional space) as a subspace, it must have
dimension at least 4001.  However, note that we can replace the number 4000 by any positive integer $n$.
The dimension of $\mathbb{P}$ must be at least $n+1$ for any such $n$.  The only way this is possible if
if $\mathbb{P}$ has no finite dimension.   
}

\endedxproblem




\endedxvertical




\beginedxvertical{More Subspace Questions}


\beginedxproblem{Subspace 1}{\dpa1}

True or False: If $W$ is a subspace of $V$, and the dimension of $W$ and the dimension of $V$ are both 8,
then $W = V$.  

\edXabox{expect="True" options="True","False"}

\edXsolution{
This is a direct consequence of one of the propositions on the previous page.  
}

\endedxproblem

\beginedxproblem{Subspace 2}{\dpa1}

True or False: If $W$ is a subspace of $V$, and both $W$ and $V$ are infinite-dimensional,
then $W=V$.  

\edXabox{expect="False" options="True","False"}

\edXsolution{
False.  The proposition does not apply to infinite-dimensional spaces.  For instance,
if $V$ is the vector space of all functions on $\R$, and $W$ is the space of polynomials $\mathbb{P}$ (which
is a subspace of the space of all functions),
then both $V$ and $W$ are infinite-dimensional, but $W\ne V$.  
}

\endedxproblem


\endedxvertical
